import type { Project } from "@/features/portfolio/types/projects";

export const PROJECTS: Project[] = [
  {
    id: "cyberintel-summarizer",
    title: "CyberIntel Summarizer: Real-Time Threat Intelligence System",
    period: {
      start: "09.2024",
    },
    link: "https://github.com/PRawat00",
    demoLink: "https://cyber-intel-azure.vercel.app/",
    skills: [
      "LoRA",
      "vLLM",
      "4-bit Quantization",
      "FastAPI",
      "PostgreSQL",
      "Streamlit",
      "Dynamic Batching",
      "Paged Attention",
      "NVD",
      "CISA",
      "MITRE ATT&CK",
    ],
    summary: `Real-time cybersecurity threat intelligence system analyzing 100+ daily CVE updates from NVD, CISA, and MITRE ATT&CK feeds. Features LoRA-fine-tuned LLM with 4-bit quantization achieving 3x throughput improvement and interactive Streamlit dashboard for threat analytics.`,
    description: `Engineered end-to-end cybersecurity intelligence pipeline ingesting NVD, CISA, and MITRE ATT&CK feeds, generating LLM-powered summaries and severity classifications for 100+ daily CVE updates with automated data monitoring. Deployed LoRA-fine-tuned model with 4-bit quantization using vLLM, achieving 3x throughput improvement and 60% memory reduction compared to FP16 baseline through dynamic batching and paged attention. Built production-ready API (FastAPI, PostgreSQL) with Streamlit dashboard displaying real-time threat analytics by severity, attack vector, and vendor, with interactive performance benchmarking across inference configurations.`,
    logo: "CI",
    image: "/r/CyberIntel__.gif",
    isExpanded: true,
  },
  {
    id: "wegmans-capstone",
    title: "Gluten Sensitivity Prediction System (Wegmans Capstone)",
    period: {
      start: "08.2024",
      end: "12.2024",
    },
    link: "https://github.com/PRawat00",
    skills: [
      "XGBoost",
      "Feature Engineering",
      "Class Imbalance",
      "Threshold Optimization",
      "Cost-Sensitive Learning",
      "F1-optimal",
      "Youden's J",
      "PR-AUC",
      "Business Analytics",
    ],
    summary: `XGBoost classification system analyzing 5.6M transaction records for Wegmans Food Market. Implemented threshold optimization improving precision by 49% while demonstrating reduced coupon waste and higher marketing ROI.`,
    description: `Built XGBoost classification models on 5.6M transaction records to predict gluten sensitivity, feature engineering (purchase cadence, brand preferences, substitution patterns) and handling severe class imbalance using undersampling and cost-weighted learning. Designed a threshold optimization framework across 4 strategies (F1-optimal, Youden's J, cost-weighted FN:FP, PR-AUC), improving precision by 49% while maintaining sensitivity for imbalanced classification. Conducted cost-sensitive analysis to quantify business trade-offs between false positives and false negatives, demonstrating reduced coupon waste and higher marketing ROI through optimized targeting.`,
    logo: "/images/companies/Wegamans_logo.jpeg",
    image: "/r/Wegmans_Image.png",
    isExpanded: false,
  },

  // Temporarily commented out projects - can be uncommented when needed
  /*
  {
    id: "realtime-tweet-sentiment",
    title: "Real-Time Tweet Sentiment Analysis Pipeline",
    period: {
      start: "01.2025",
      end: "03.2025",
    },
    link: "https://github.com/PRawat00",
    skills: [
      "Apache Spark Streaming",
      "Delta Lake",
      "Hugging Face Transformers",
      "MLflow",
      "Databricks",
      "Grafana",
      "Data Quality Validation",
      "Medallion Architecture",
      "Auto-scaling",
      "Real-time Processing",
    ],
    summary: `Real-time sentiment analysis pipeline processing 50K+ tweets per hour with 99.5% uptime. MLflow-packaged Hugging Face transformer achieving 92% accuracy with sub-200ms latency and Grafana monitoring for sentiment anomalies.`,
    description: `Comprehensive real-time data pipeline for analyzing tweet sentiment at scale, processing 50K+ tweets per hour through Bronze, Silver, Gold, and Application layers with 99.5% uptime. Deployed MLflow-packaged Hugging Face transformer achieving 92% accuracy with sub-200ms inference latency. Implemented auto-scaling Databricks clusters with optimized partitioning strategies, reducing query response times by 65% and enabling real-time aggregations across 1M+ tweet mentions. Engineered comprehensive monitoring system with Grafana dashboards and automated alerting for sentiment anomalies.`,
    logo: "/images/projects/realtime-tweet-sentiment.svg",
    image: "/images/projects/placeholders/data-pipeline.svg",
    isExpanded: false,
  },
  {
    id: "steam-insights",
    title: "Steam Insights (Gaming Market Analysis & Forecasting)",
    period: {
      start: "08.2024",
      end: "12.2024",
    },
    link: "https://github.com/PRawat00",
    skills: [
      "Apache Airflow",
      "Databricks Spark",
      "Kafka",
      "XGBoost",
      "Random Forest",
      "ARIMA",
      "Prophet",
      "Python",
    ],
    summary: `Gaming market analysis system processing 8M+ data points from 140K+ games with ETL pipeline using Airflow, Spark, and Kafka. Time series forecasting achieving 85% accuracy in genre demand predictions.`,
    description: `Comprehensive gaming market analysis and forecasting system processing 8M+ data points from 140K+ games. Built ETL pipeline with Apache Airflow, Databricks Spark, and Kafka. Developed ML models (XGBoost, Random Forest) for review analysis and pricing forecasts. Implemented time series forecasting (ARIMA, Prophet) achieving 85% accuracy in genre demand predictions and reliable sales forecasting.`,
    logo: "/images/projects/steam-insights.svg",
    image: "/images/projects/placeholders/gaming-analytics.svg",
    isExpanded: true,
  },
  {
    id: "finrag3",
    title: "FinRAG3 - Agentic Financial Document AI",
    period: {
      start: "02.2025",
    },
    link: "https://github.com/PRawat00",
    skills: [
      "LangGraph",
      "LangChain",
      "ChromaDB",
      "ColBERT v2",
      "FastAPI",
      "Docker",
      "GPU Computing",
    ],
    description: `6-phase agentic AI system for automated investment due diligence processing SEC filings (10-K, 10-Q) and fund prospectuses. Features custom parsing algorithms with 95% accuracy, multi-GPU optimization, and enterprise-grade MLOps pipeline. Reduces financial document analysis time from hours to 5 minutes.`,
    logo: "/images/projects/finrag3.svg",
    isExpanded: false,
  },
  {
    id: "hpc-chatbot",
    title: "HPC Documentation Assistant",
    period: {
      start: "02.2025",
    },
    link: "https://github.com/PRawat00",
    skills: [
      "RAG Systems",
      "Vector Databases",
      "FastAPI",
      "Docker",
      "HPC Systems",
      "Agentic AI",
    ],
    description: `RAG-based chatbot for High Performance Computing documentation automation. Features agentic AI for dynamic data scraping, vector database management for HPC queries, and automated user onboarding system for university research computing infrastructure.`,
    logo: "/images/projects/hpc-chatbot.svg",
    isExpanded: false,
  },
  {
    id: "health-analytics",
    title: "Health Analytics Platform",
    period: {
      start: "01.2023",
      end: "03.2023",
    },
    link: "https://github.com/PRawat00",
    skills: [
      "Django",
      "MongoDB",
      "LLaMA",
      "FactCC",
      "RAG Systems",
      "spaCy",
      "NLP",
      "Web Scraping",
    ],
    description: `End-to-end health analytics platform using Django and MongoDB for SSOT data collection. Implemented RAG approach with LLaMA and FactCC for accurate health summaries. Built NLP pipeline with spaCy and LSA for health trend extraction. Achieved 60% increase in data availability and 75% reduction in manual errors through adaptive web scraping.`,
    logo: "/images/projects/health-analytics.svg",
    isExpanded: false,
  },
  */
];
